{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reward = level_player * level_food creating a clear incentive to cooperate\n",
    "- learning to navigate the world is not needed. One could simplify use the action space: Of all available foods choose one where to go given its location, level and the position of the other players. Would make interpretation better as one could see which food was targeted. First progeam a basic rl algorithm (look into marllib). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lbforaging\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the enviromente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the environment in gym\n",
    "\n",
    "field_size = 8 # size of the game board\n",
    "number_players = 1 # Number of players\n",
    "max_num_food = 63 # max amount of food on the board. TODO How is teh amount of food determined?\n",
    "coop_mode = False # If true, all foods will have teh max level so that all foods can only be loaded by working with other players\n",
    "max_episode_steps = 50 # Number of steps until one round (episode) is terminated\n",
    "sight = field_size #  How far can the agents see i presume TODO\n",
    "max_player_level = 2\n",
    "min_player_level = 2\n",
    "max_food_level = 2\n",
    "min_food_level = 2\n",
    "\n",
    "id_string = \"Foraging-{0}x{0}-{1}p-{2}f{3}-v3\".format(field_size, number_players, max_num_food, \"-coop\" if coop_mode else \"\")\n",
    "\n",
    "gym.envs.registration.register(\n",
    "    id=id_string,\n",
    "    entry_point=\"lbforaging.foraging:ForagingEnv\",\n",
    "    kwargs={\n",
    "        \"players\": number_players,\n",
    "        \"max_player_level\": max_player_level,\n",
    "        \"min_player_level\": min_player_level, \n",
    "        \"max_food_level\": max_food_level,\n",
    "        \"min_food_level\": min_food_level,\n",
    "        \"field_size\": (field_size, field_size),\n",
    "        \"max_num_food\": max_num_food,\n",
    "        \"sight\": sight,\n",
    "        \"max_episode_steps\": max_episode_steps,\n",
    "        \"force_coop\": coop_mode,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the environment. A more detailed way is discribed on https://github.com/semitable/lb-foraging\n",
    "env = gym.make(id_string) # \"Foraging-{GRID_SIZE}x{GRID_SIZE}-{PLAYER COUNT}p-{FOOD LOCATIONS}f{-coop IF COOPERATIVE MODE}-v0\"\n",
    "# render_mode is \"human\" per default\n",
    "\n",
    "# reset the environment with a seed\n",
    "observation, info = env.reset(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\coding_projects\\lbf_marl\\.venv\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:245: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game lasted 50 steps\n"
     ]
    }
   ],
   "source": [
    "# generate one step of teh game saving the observations, rewards, tasks done, trancuated (?) and info (?)\n",
    "episode_over = False\n",
    "step_amount = 0\n",
    "while not episode_over:\n",
    "    action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    for i in range(50):\n",
    "        env.render() # TODO: work with timestart and timeend here to get actual frame rate\n",
    "    episode_over = terminated or truncated\n",
    "    step_amount += 1\n",
    "env.close()\n",
    "print(f\"Game lasted {step_amount} steps\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
