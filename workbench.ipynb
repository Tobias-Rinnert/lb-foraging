{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. get all fruits that the player can load either alone or with others\n",
    "2. for each of these fruits calculate summery statistics\n",
    "3. for each player make a prediciton for each of the fruits and save the result in a dictionary for each player. id fruits and prob\n",
    "4. given the first order believes about the othe players, choose the next target and give teh result as training back to teh prediction for the player\n",
    "5. When another player loads a fruit, train the neural network with the results by mapping it with the id. \n",
    "\n",
    "So the nn is trained to predict the reqard maximizing choice of a player given the choices of other players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reward = level_player * level_food creating a clear incentive to cooperate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lbforaging\n",
    "import gymnasium as gym\n",
    "from lbforaging.agents import H1\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from tr_lbf_addon.lbf_gym import Lbf_Gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the enviromente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the environment in gym\n",
    "\n",
    "field_size = 8 # size of the game board\n",
    "number_players = 2 # Number of players\n",
    "max_num_food = 8 # max amount of food on the board. TODO How is teh amount of food determined?\n",
    "coop_mode = False # If true, all foods will have teh max level so that all foods can only be loaded by working with other players\n",
    "max_episode_steps = 50 # Number of steps until one round (episode) is terminated\n",
    "sight = 0  #  How far can the agents see i presume TODO\n",
    "max_player_level = 1\n",
    "min_player_level = 1\n",
    "max_food_level = 1\n",
    "min_food_level = 1\n",
    "normalize_reward = True\n",
    "grid_observation = False\n",
    "observe_agent_levels = True # If true, the observation will include the level of the agents\n",
    "penalty = 0.0 # if the player was not the one to load the food, it gets a penalty to its reward\n",
    "render_mode = \"human\"\n",
    "full_info_mode = True\n",
    "\n",
    "id_string = \"Foraging-{0}x{0}-{1}p-{2}f{3}-v3\".format(field_size, number_players, max_num_food, \"-coop\" if coop_mode else \"\")\n",
    "\n",
    "gym.envs.registration.register(\n",
    "    id=id_string,\n",
    "    entry_point=\"lbforaging.foraging:ForagingEnv\",\n",
    "    kwargs={\n",
    "        \"players\": number_players,\n",
    "        \"max_player_level\": max_player_level,\n",
    "        \"min_player_level\": min_player_level, \n",
    "        \"max_food_level\": max_food_level,\n",
    "        \"min_food_level\": min_food_level,\n",
    "        \"field_size\": (field_size, field_size),\n",
    "        \"max_num_food\": max_num_food,\n",
    "        \"sight\": sight,\n",
    "        \"max_episode_steps\": max_episode_steps,\n",
    "        \"force_coop\": coop_mode,\n",
    "        \"normalize_reward\" : normalize_reward,\n",
    "        \"grid_observation\" : grid_observation,\n",
    "        \"observe_agent_levels\" : observe_agent_levels,\n",
    "        \"penalty\" : penalty,\n",
    "        \"render_mode\" : render_mode,\n",
    "        \"full_info_mode\": full_info_mode\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the environment. A more detailed way is discribed on https://github.com/semitable/lb-foraging\n",
    "env = gym.make(id_string) # \"Foraging-{GRID_SIZE}x{GRID_SIZE}-{PLAYER COUNT}p-{FOOD LOCATIONS}f{-coop IF COOPERATIVE MODE}-v0\"\n",
    "# render_mode is \"human\" per default\n",
    "\n",
    "# reset the environment with a seed\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# initialize the class\n",
    "tr_marla_class = Lbf_Gym(observation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8, 10, 12, 14, 16, 18, 20])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "levels = [8,2,6,4]\n",
    "\n",
    "duo_coop_levels = pd.Series([np.sum(levels) for levels in list(itertools.combinations(levels, 2))]).unique().tolist()\n",
    "tripple_coop_levels = pd.Series([np.sum(levels) for levels in list(itertools.combinations(levels, 3))]).unique().tolist()\n",
    "squad_coop_levels = pd.Series([np.sum(levels) for levels in list(itertools.combinations(levels, 4))]).unique().tolist()\n",
    "\n",
    "res = np.sort(pd.Series(duo_coop_levels + tripple_coop_levels + squad_coop_levels).unique())\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game lasted 18 steps\n"
     ]
    }
   ],
   "source": [
    "episode_over = False\n",
    "step_amount = 0\n",
    "while not episode_over:\n",
    "    tr_marla_class.update_observation(observation[0])\n",
    "    actions = tr_marla_class.agents_choose_actions()\n",
    "    observation, reward, terminated, truncated, info = env.step(tuple(actions))\n",
    "    # let 2 senconds pass\n",
    "    env.render()\n",
    "    time.sleep(0.2)\n",
    "    episode_over = terminated or truncated\n",
    "    step_amount += 1\n",
    "env.close()\n",
    "print(f\"Game lasted {step_amount} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_marla_class.update_observation(observation[0])\n",
    "actions = tr_marla_class.agents_choose_actions()\n",
    "observation, reward, terminated, truncated, info = env.step(tuple(actions))\n",
    "tr_marla_class.full_info_field"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
